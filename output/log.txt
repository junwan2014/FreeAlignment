[04/24 10:48:59] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:48:59] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:48:59] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:48:59] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS: './output/prompt_model_0015000.pth'
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 1
[04/24 10:48:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: ./output/prompt_model_0015000.pth
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:48:59] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:52:01] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:52:01] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:52:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:52:01] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS: './output/prompt_model_0015000.pth'
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 1
[04/24 10:52:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: ./output/prompt_model_0015000.pth
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:52:01] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:52:03] d2.engine.defaults INFO: Model:
ProposalClipClassifier(
  (clip_adapter): ClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 10:52:03] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/prompt_model_0015000.pth ...
[04/24 10:52:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/prompt_model_0015000.pth ...
[04/24 10:52:22] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:52:22] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:52:22] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:52:22] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS: 
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 1
[04/24 10:52:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:52:22] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:52:24] d2.engine.defaults INFO: Model:
ProposalClipClassifier(
  (clip_adapter): ClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 10:52:24] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 10:52:24] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 10:54:18] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:54:19] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:54:19] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:54:19] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS:
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 1
[04/24 10:54:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:54:19] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:54:20] d2.engine.defaults INFO: Model:
ProposalClipClassifier(
  (clip_adapter): ClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 10:54:36] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:54:36] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:54:36] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:54:36] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:54:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 10:54:36] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 10:54:36] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 10:54:50] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 561, in after_step
    current_rmse = self._do_eval()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 530, in _do_eval
    results = self._func()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 468, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 620, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\train_net.py", line 226, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name, mapper=mapper)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\config\config.py", line 207, in wrapped
    explicit_args = _get_args_from_config(from_config, *args, **kwargs)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\config\config.py", line 245, in _get_args_from_config
    ret = from_config_func(*args, **kwargs)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\data\build.py", line 297, in _test_loader_from_config
    dataset = get_detection_dataset_dicts(
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\data\build.py", line 131, in get_detection_dataset_dicts
    temp = wrap_metas(DatasetCatalog.get(dataset_name), dataset_name=dataset_name) #D:\python_work\lib\detectron_repo\detectron2\data\datasets\coco.py line 268
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\data\catalog.py", line 58, in get
    return f()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\data\datasets\register_300w.py", line 160, in <lambda>
    DatasetCatalog.register(all_name,lambda: load_sem_seg_300w(root, val_json, max_num, 'test'),)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\data\datasets\coco.py", line 281, in load_sem_seg_300w
    record["file_name"] = root + landmarks_frame.iloc[idx, 0]
  File "C:\anaconda3\envs\freealign\lib\site-packages\pandas\core\indexing.py", line 1096, in __getitem__
    return self.obj._get_value(*key, takeable=self._takeable)
  File "C:\anaconda3\envs\freealign\lib\site-packages\pandas\core\frame.py", line 3868, in _get_value
    return series._values[index]
IndexError: index 135 is out of bounds for axis 0 with size 135
[04/24 10:54:50] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[04/24 10:54:50] d2.utils.events INFO:  iter: 1  total_loss: 1.81   lr: 0.0001
[04/24 10:55:35] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:55:35] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:55:35] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:55:35] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS:
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 100000 #not needed, set to a large number
[04/24 10:55:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:55:35] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:55:37] d2.engine.defaults INFO: Model:
ProposalClipClassifier(
  (clip_adapter): ClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 10:55:53] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:55:53] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:55:53] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:55:53] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:55:53] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 10:55:53] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 10:55:53] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 10:56:07] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 207, in after_step
    self.step(self.trainer.iter, best_rmse)
TypeError: step() takes 2 positional arguments but 3 were given
[04/24 10:56:07] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[04/24 10:56:07] d2.utils.events INFO:  iter: 1  total_loss: 1.81   lr: 0.0001
[04/24 10:56:41] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:56:42] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:56:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:56:42] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS:
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 100000 #not needed, set to a large number
[04/24 10:56:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:56:42] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:56:43] d2.engine.defaults INFO: Model:
ProposalClipClassifier(
  (clip_adapter): ClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 10:56:59] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:56:59] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:56:59] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:56:59] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 10:56:59] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 10:56:59] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 10:56:59] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 10:57:39] d2.utils.events INFO:  eta: 0:22:24  iter: 100  total_loss: 1.76   lr: 0.0001
[04/24 10:58:07] d2.utils.events INFO:  eta: 0:22:16  iter: 200  total_loss: 1.34   lr: 0.019992
[04/24 10:58:33] d2.utils.events INFO:  eta: 0:22:13  iter: 300  total_loss: 1.25   lr: 0.019983
[04/24 10:59:47] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 10:59:48] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 10:59:48] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 10:59:48] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_learn_prompt_bs32_16k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
ORACLE: True

MODEL:
  WEIGHTS:
  META_ARCHITECTURE: "ProposalClipClassifier"
  MASK_ON: True
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
DATASETS: #D:\python_work\FaceAlignment\Universal Alignment\FreeAlignment-main\mask2former\config.py lin 121
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", 'COFW_val') #"300W_val",'WFLW_val','COFW_val', 'AFLW_val'
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [224, 224]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  BOUNDARY: ['left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
#  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
#                           [26, 30, 33, 37, 40, 42, 45, 48],
#                           [49, 50, 51, 52, 53],
#                           [58, 59, 60, 61, 62],
#                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
#                           [78, 80, 83, 84, 86, 88],
#                           [90, 91, 94, 96, 98, 100],
#                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], #left, right chin
                           [17, 18, 19, 20, 21], [22, 23, 24, 25, 26], #left right brow
                           [27, 28, 29, 30, 31, 32, 33, 34, 35], #nose
                           [36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], #left right eye
                           [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]] #mouth

  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                    78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                    122, 123, #pupil 2 (16, 17)
                    76, 77, 70, 73,  # //nose 4 (18-21)
                    102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                    24, # chin 1  (28)
                    124 ] #background

  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                            [ 0, 2, 4, 5], [ 1, 3, 6, 7 ], #left right brow 8
                            [ 18, 19, 20, 21], #nose 4
                            [ 8, 10, 12, 13, 16 ], [9, 11, 14, 15, 17], #left right eye 10
                            [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                            [ 0, 1, 2], [ 3, 4, 5], #left right brow 8
                            [ 12, 13, 14], #nose 4
                            [ 6, 7, 8], [9, 10, 11], #left right eye 10
                            [ 15, 16, 17] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], #left, right chin
                            [33, 34, 35, 36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47, 48, 49, 50], #left, right brow
                            [51, 52, 53, 54, 55, 56, 57, 58, 59], # nose
                            [60, 61, 62, 63, 64, 65, 66, 67, 96], [68, 69, 70, 71, 72, 73, 74, 75, 97], #left right eye
                            [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]] #mouth
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                    25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                    67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                    78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                    102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                    122, 123, # pupil 2 (96-97) background
                    124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                    78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                    76, 70, 77,  # nose 3 (12-14)
                    102, 120, 108,  # mouth 3 (15-17)
                    24, # chin 1 (18)
                    124 ] #background

INPUT:
  MIN_SIZE_TRAIN: (224,244)
  MIN_SIZE_TEST: 224
  MAX_SIZE_TEST: 2560
  SIZE_DIVISIBILITY: -1
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_alignment" #mask_former_full_binary_semantic
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']
SOLVER:
  MODE: 'prompt'
  OPTIMIZER: "SGD"
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.001
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  WARMUP_METHOD: "constant"  
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  IMS_PER_BATCH: 32 #32
  TEST_IMS_PER_BATCH: 4
  MAX_ITER: 16010
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 100000 #not needed, set to a large number
[04/24 10:59:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 224
  - 224
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 224
  MIN_SIZE_TRAIN:
  - 224
  - 244
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: -1
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ''
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: true
  META_ARCHITECTURE: ProposalClipClassifier
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: true
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 32
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 16010
  MODE: prompt
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: SGD
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 4
  WARMUP_FACTOR: 0.005
  WARMUP_ITERS: 100
  WARMUP_METHOD: constant
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 10:59:48] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 10:59:50] d2.engine.defaults INFO: Model:
ProposalClipClassifier(
  (clip_adapter): ClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 11:00:05] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 11:00:05] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 11:00:05] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 11:00:05] d2.data.build INFO: Making batched data loader with batch_size=32
[04/24 11:00:05] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 11:00:05] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 11:00:05] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 11:01:35] d2.utils.events INFO:  eta: 1:43:28  iter: 100  total_loss: 1.98   lr: 0.0001
[04/24 11:02:15] d2.utils.events INFO:  eta: 1:42:29  iter: 200  total_loss: 1.47   lr: 0.019992
[04/24 11:02:55] d2.utils.events INFO:  eta: 1:42:16  iter: 300  total_loss: 1.26   lr: 0.019983
[04/24 11:03:31] d2.engine.hooks INFO: Overall training speed: 385 iterations in 0:02:33 (0.3998 s / it)
[04/24 11:03:31] d2.engine.hooks INFO: Total training time: 0:02:34 (0:00:00 on hooks)
[04/24 11:03:31] d2.utils.events INFO:  eta: 1:42:16  iter: 388  total_loss: 1.18   lr: 0.019971
[04/24 11:05:36] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 11:05:36] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 11:05:36] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 11:05:36] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 401

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/24 11:05:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 401
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 11:05:37] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 11:05:39] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 11:05:54] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:05:54] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:05:54] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:05:54] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:05:55] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 11:05:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 11:05:55] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 11:11:31] d2.utils.events INFO:  eta: 1 day, 23:35:59  iter: 100  total_loss: 55.8  loss_ce: 1.15  loss_mask: 0.266  loss_dice: 4.75  loss_ce_land: 14.7  loss_land_coords: 34.3  N_B_300W: 0.543  N_B_AFLW: 0.179  N_B_COFW: 0.613  N_B_WFLW: 0.577 lr: 2.025e-06
[04/24 11:16:15] d2.utils.events INFO:  eta: 1 day, 23:18:46  iter: 200  total_loss: 22.4  loss_ce: 0.781  loss_mask: 0.266  loss_dice: 4.65  loss_ce_land: 10.2  loss_land_coords: 6.57  N_B_300W: 0.115  N_B_AFLW: 0.0393  N_B_COFW: 0.115  N_B_WFLW: 0.17 lr: 4.014e-06
[04/24 11:20:55] d2.utils.events INFO:  eta: 1 day, 22:55:29  iter: 300  total_loss: 20.2  loss_ce: 0.317  loss_mask: 0.33  loss_dice: 4.28  loss_ce_land: 9.15  loss_land_coords: 6.01  N_B_300W: 0.101  N_B_AFLW: 0.038  N_B_COFW: 0.105  N_B_WFLW: 0.142 lr: 5.997e-06
[04/24 11:25:33] d2.utils.events INFO:  eta: 1 day, 22:38:32  iter: 400  total_loss: 19.2  loss_ce: 0.197  loss_mask: 0.345  loss_dice: 3.83  loss_ce_land: 9.06  loss_land_coords: 5.57  N_B_300W: 0.0924  N_B_AFLW: 0.0375  N_B_COFW: 0.102  N_B_WFLW: 0.128 lr: 7.974e-06
[04/24 11:25:36] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 563, in after_step
    current_rmse = self._do_eval()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 532, in _do_eval
    results = self._func()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 468, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 620, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\train_net.py", line 226, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name, mapper=mapper)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\config\config.py", line 207, in wrapped
    explicit_args = _get_args_from_config(from_config, *args, **kwargs)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\config\config.py", line 245, in _get_args_from_config
    ret = from_config_func(*args, **kwargs)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\data\build.py", line 297, in _test_loader_from_config
    dataset = get_detection_dataset_dicts(
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\data\build.py", line 131, in get_detection_dataset_dicts
    temp = wrap_metas(DatasetCatalog.get(dataset_name), dataset_name=dataset_name) #D:\python_work\lib\detectron_repo\detectron2\data\datasets\coco.py line 268
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\data\catalog.py", line 58, in get
    return f()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\data\datasets\register_300w.py", line 160, in <lambda>
    DatasetCatalog.register(all_name,lambda: load_sem_seg_300w(root, val_json, max_num, 'test'),)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\data\datasets\coco.py", line 281, in load_sem_seg_300w
    record["file_name"] = root + landmarks_frame.iloc[idx, 0]
  File "C:\anaconda3\envs\freealign\lib\site-packages\pandas\core\indexing.py", line 1096, in __getitem__
    return self.obj._get_value(*key, takeable=self._takeable)
  File "C:\anaconda3\envs\freealign\lib\site-packages\pandas\core\frame.py", line 3868, in _get_value
    return series._values[index]
IndexError: index 135 is out of bounds for axis 0 with size 135
[04/24 11:25:36] d2.engine.hooks INFO: Overall training speed: 398 iterations in 0:18:44 (2.8248 s / it)
[04/24 11:25:36] d2.engine.hooks INFO: Total training time: 0:18:44 (0:00:00 on hooks)
[04/24 11:25:36] d2.utils.events INFO:  eta: 1 day, 22:38:28  iter: 401  total_loss: 19.2  loss_ce: 0.202  loss_mask: 0.345  loss_dice: 3.83  loss_ce_land: 9.06  loss_land_coords: 5.57  N_B_300W: 0.0924  N_B_AFLW: 0.0375  N_B_COFW: 0.102  N_B_WFLW: 0.128 lr: 7.9937e-06
[04/24 11:27:59] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 11:28:00] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 11:28:00] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 11:28:00] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/24 11:28:00] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 11:28:00] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 11:28:03] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 11:28:28] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:28:28] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:28:28] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:28:28] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:28:28] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 11:28:28] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 11:28:28] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 11:31:10] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 563, in after_step
    current_rmse = self._do_eval()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 532, in _do_eval
    results = self._func()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 468, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 635, in test
    results_i = inference_on_dataset(model, data_loader, name_tmp, evaluator)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\evaluation\evaluator.py", line 176, in inference_on_dataset
    evaluator.process(inputs, outputs, outputs_flip)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\evaluation\panoptic_seg_evaluation.py", line 165, in process
    Image.fromarray(id2rgb(panoptic_img)).save(out, format="PNG")
  File "C:\anaconda3\envs\freealign\lib\site-packages\panopticapi-0.1-py3.8.egg\panopticapi\utils.py", line 88, in id2rgb
    id_map_copy //= 256
numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'floor_divide' output from dtype('int16') to dtype('uint8') with casting rule 'same_kind'
[04/24 11:31:17] d2.engine.hooks INFO: Total training time: 0:00:49 (0:00:49 on hooks)
[04/24 11:31:17] d2.utils.events INFO:  iter: 1  total_loss: 81.9  loss_ce: 2.34  loss_mask: 4.36  loss_dice: 4.77  loss_ce_land: 20.2  loss_land_coords: 48.9  N_B_300W: 0.653  N_B_AFLW: 0.306  N_B_COFW: 0.81  N_B_WFLW: 0.683 lr: 5e-08
[04/24 11:33:35] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 11:33:36] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 11:33:36] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 11:33:36] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/24 11:33:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 11:33:36] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 11:33:39] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 11:34:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:34:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:34:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:34:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:34:04] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 11:34:04] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 11:34:04] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 11:37:10] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 563, in after_step
    current_rmse = self._do_eval()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 532, in _do_eval
    results = self._func()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 468, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 635, in test
    results_i = inference_on_dataset(model, data_loader, name_tmp, evaluator)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\evaluation\evaluator.py", line 176, in inference_on_dataset
    evaluator.process(inputs, outputs, outputs_flip)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\evaluation\panoptic_seg_evaluation.py", line 165, in process
    Image.fromarray(id2rgb(panoptic_img)).save(out, format="PNG")
  File "C:\anaconda3\envs\freealign\lib\site-packages\panopticapi-0.1-py3.8.egg\panopticapi\utils.py", line 88, in id2rgb
    id_map_copy //= 256
numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'floor_divide' output from dtype('int16') to dtype('uint8') with casting rule 'same_kind'
[04/24 11:37:10] d2.engine.hooks INFO: Total training time: 0:01:39 (0:01:39 on hooks)
[04/24 11:37:10] d2.utils.events INFO:  iter: 1  total_loss: 81.9  loss_ce: 2.34  loss_mask: 4.36  loss_dice: 4.77  loss_ce_land: 20.2  loss_land_coords: 48.9  N_B_300W: 0.653  N_B_AFLW: 0.306  N_B_COFW: 0.81  N_B_WFLW: 0.683 lr: 5e-08
[04/24 11:43:54] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 11:43:54] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 11:43:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 11:43:54] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/24 11:43:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 11:43:55] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 11:43:57] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 11:44:22] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:44:22] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:44:22] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:44:22] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:44:22] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 11:44:22] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 11:44:22] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 11:48:09] detectron2 INFO: Rank of current process: 0. World size: 1
[04/24 11:48:09] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/24 11:48:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/24 11:48:09] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/24 11:48:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/24 11:48:09] detectron2 INFO: Full config saved to ./output\config.yaml
[04/24 11:48:12] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/24 11:48:37] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:48:37] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:48:37] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:48:37] d2.data.build INFO: Making batched data loader with batch_size=8
[04/24 11:48:37] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/24 11:48:37] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/24 11:48:37] d2.engine.train_loop INFO: Starting training from iteration 0
[04/24 11:51:42] d2.evaluation.evaluator INFO: Inference done 101/135. Dataloading: 0.0004 s/iter. Inference: 0.5268 s/iter. Eval: 0.0065 s/iter. Total: 0.5337 s/iter. ETA=0:00:18
[04/24 11:52:15] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 563, in after_step
    current_rmse = self._do_eval()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 532, in _do_eval
    results = self._func()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 468, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 635, in test
    results_i = inference_on_dataset(model, data_loader, name_tmp, evaluator)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\evaluation\evaluator.py", line 199, in inference_on_dataset
    results = evaluator.evaluate(name_tmp)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\evaluation\panoptic_seg_evaluation.py", line 204, in evaluate
    pq_res = pq_compute( #C:\anaconda3\envs\py38\Lib\site-packages\panopticapi\evaluation.py
  File "C:\anaconda3\envs\freealign\lib\site-packages\panopticapi-0.1-py3.8.egg\panopticapi\evaluation.py", line 224, in pq_compute
    results[name], per_class_results = pq_stat.pq_average(categories, isthing=isthing)
  File "C:\anaconda3\envs\freealign\lib\site-packages\panopticapi-0.1-py3.8.egg\panopticapi\evaluation.py", line 73, in pq_average
    return {'pq': pq / n, 'sq': sq / n, 'rq': rq / n, 'n': n}, per_class_results
ZeroDivisionError: division by zero
[04/24 11:52:15] d2.engine.hooks INFO: Total training time: 0:02:13 (0:02:13 on hooks)
[04/24 11:52:15] d2.utils.events INFO:  iter: 1  total_loss: 81.9  loss_ce: 2.34  loss_mask: 4.36  loss_dice: 4.77  loss_ce_land: 20.2  loss_land_coords: 48.9  N_B_300W: 0.653  N_B_AFLW: 0.306  N_B_COFW: 0.81  N_B_WFLW: 0.683 lr: 5e-08
[04/28 09:41:12] detectron2 INFO: Rank of current process: 0. World size: 1
[04/28 09:41:13] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/28 09:41:13] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/28 09:41:13] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/28 09:41:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/28 09:41:13] detectron2 INFO: Full config saved to ./output\config.yaml
[04/28 09:41:16] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/28 09:41:31] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 09:41:31] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 09:41:31] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 09:41:31] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 09:41:31] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/28 09:41:31] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/28 09:41:31] d2.engine.train_loop INFO: Starting training from iteration 0
[04/28 09:43:24] d2.evaluation.evaluator INFO: Inference done 101/135. Dataloading: 0.0003 s/iter. Inference: 0.5335 s/iter. Eval: 0.0064 s/iter. Total: 0.5402 s/iter. ETA=0:00:18
[04/28 09:43:57] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 158, in train
    self.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\train_loop.py", line 192, in after_step
    h.after_step(best_rmse)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 563, in after_step
    current_rmse = self._do_eval()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\hooks.py", line 532, in _do_eval
    results = self._func()
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 468, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\engine\defaults.py", line 635, in test
    results_i = inference_on_dataset(model, data_loader, name_tmp, evaluator)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\evaluation\evaluator.py", line 199, in inference_on_dataset
    results = evaluator.evaluate(name_tmp)
  File "D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\mask2former\evaluation\panoptic_seg_evaluation.py", line 204, in evaluate
    pq_res = pq_compute( #C:\anaconda3\envs\py38\Lib\site-packages\panopticapi\evaluation.py
  File "C:\anaconda3\envs\freealign\lib\site-packages\panopticapi-0.1-py3.8.egg\panopticapi\evaluation.py", line 224, in pq_compute
    results[name], per_class_results = pq_stat.pq_average(categories, isthing=isthing)
  File "C:\anaconda3\envs\freealign\lib\site-packages\panopticapi-0.1-py3.8.egg\panopticapi\evaluation.py", line 73, in pq_average
    return {'pq': pq / n, 'sq': sq / n, 'rq': rq / n, 'n': n}, per_class_results
ZeroDivisionError: division by zero
[04/28 09:43:57] d2.engine.hooks INFO: Total training time: 0:01:31 (0:01:31 on hooks)
[04/28 09:43:57] d2.utils.events INFO:  iter: 1  total_loss: 81.9  loss_ce: 2.34  loss_mask: 4.36  loss_dice: 4.77  loss_ce_land: 20.2  loss_land_coords: 48.9  N_B_300W: 0.653  N_B_AFLW: 0.306  N_B_COFW: 0.81  N_B_WFLW: 0.683 lr: 5e-08
[04/28 10:02:46] detectron2 INFO: Rank of current process: 0. World size: 1
[04/28 10:02:46] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                            1.24.1
detectron2                       0.6 @D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2
Compiler                         MSVC 193532217
CUDA compiler                    CUDA 11.8
detectron2 arch flags            D:\python_work\FaceAlignment\FreeAlign\FreeAlignment-main\detectron_repo\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4090 (arch=8.9)
Driver version                   560.94
CUDA_HOME                        C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
Pillow                           10.2.0
torchvision                      0.15.2+cu118 @C:\anaconda3\envs\freealign\lib\site-packages\torchvision
torchvision arch flags           C:\anaconda3\envs\freealign\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 193431937
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/28 10:02:46] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[04/28 10:02:46] detectron2 INFO: Contents of args.config_file=./configs/face-align/mask2former_R101c_alldataset_bs32_60k.yaml:
_BASE_: ../face-align-base/mask2former_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 156
    TEST:
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  WEIGHTS:
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 8 #only used in set criterion
    EMBEDDING_DIM: 512
    LAND_CLASSES: 125 # D:\python_work\FaceAlignment\Universal Alignment\FreeAlignmentT\mask2former\modeling\transformer\open_transformer_predictor.py line 71
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  EXTRA:
    AUX_LOSS: True
    KPT_LOSS_COEF: 5.0
    EOS_COEF: 0.1
    DEC_LAYERS: 10
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.8
    PROMPT_CHECKPOINT: './output/prompt_model_0015000.pth'    #  './output/prompt_model_0015000.pth' './output/model_0014999.pth'
INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_alignment"
  TASK_NAME: ["300W.",  "COFW.",  "AFLW.", 'WFLW.']

SOLVER:
  IMS_PER_BATCH: 8 #8
  TEST_IMS_PER_BATCH: 1
  MODE: 'predict'
  BASE_LR: 0.00005 # 0.00005 (9-pan)
  WEIGHT_DECAY: 0.00005  # 0.00005 (9-pan)
  WARMUP_FACTOR: 0.001
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5001
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 2500
  WARMUP_METHOD: "linear"
#  LR_SCHEDULER_NAME: WarmupMultiStepLR
#  IMS_PER_BATCH: 8
#  BASE_LR: 0.00005 # 0.00005
#  GAMMA: 0.1
#  WEIGHT_DECAY: 0.001  # 0.00005
#  WARMUP_FACTOR: 0.001
#  WARMUP_ITERS: 2500
#  STEPS: [2500, 20000, 35000]
#  MAX_ITER: 60000
#  CHECKPOINT_PERIOD: 5000
#  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1

DATASETS:
  TRAIN: ("300W_train",'WFLW_train','COFW_train', 'AFLW_train')  # coco_2017_train_full_task_base_classification "coco_2017_train_stuff_base_sem_seg_classification",
  TEST: ("300W_val", "COFW_val", "AFLW_val", "WFLW_val",) #"COFW_val",  "AFLW_val", "300W_val", "WFLW_val"
  MAX_IMAGE_SIZE: 20000 # AFLW datasets
  SAMPLE_PER_CLASS: 68
  INPUT_SIZE: [ 448, 448 ]
  FLIP: True
  SCALE_FACTOR: 0.25
  ROT_FACTOR: 30
  NUM_LANDMARKS: 68
  LANDMARK_INDEX_300W: [ 1, 3, 5, 8, 11, 15, 19, 22, 24,  # left chin (0-8) 24 chin center
                         26, 30, 33, 37, 40, 42, 45, 48,  # right chin (9-16)
                         49, 50, 51, 52, 53, 58, 59, 60, 61, 62,  # brow (17-26)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,   # nose 9 (27-35)
                         78, 80, 83, 84, 86, 88, 90, 91, 94, 96, 98, 100, # eyes 12 (36-47)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (48-67)
                         124 ] #background
  LANDMARK_INDEX_COFW: [ 49, 62, 53, 58, 51, 56, 60, 64,  # brow 8 (0-7)
                         78, 96, 84, 90, 81, 87, 93, 99,  # eyes 8 (8-15)
                         122, 123, #pupil 2 (16, 17)
                         76, 77, 70, 73,  # //nose 4 (18-21)
                         102, 108, 105, 116, 120, 111,  # mouth 6 (22-27)
                         24, # chin 1  (28)
                         124 ] #background
  LANDMARK_INDEX_WFLW: [ 0, 2, 4, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24,  # left chin (0-16) 24 chin center
                         25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47,  # right chin (17-32)
                         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,  # brow (33-50)
                         67, 68, 69, 70, 71, 72, 73, 74, 75,  # nose 9 (51-59)
                         78, 79, 81, 82, 84, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 101,  # eyes 16 (60-75)
                         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, # mouth 20 (76-95)
                         122, 123, # pupil 2 (96-97) background
                         124 ] #background

  LANDMARK_INDEX_AFLW: [ 49, 51, 53, 58, 60, 62,  # brow 6 (0-5)
                         78, 122, 84, 90, 123, 96,  # eyes 6 (6-11)
                         76, 70, 77,  # nose 3 (12-14)
                         102, 120, 108,  # mouth 3 (15-17)
                         24, # chin 1 (18)
                         124 ] #background
  BOUNDARY: [ 'left contour', 'right contour', 'left brow', 'right brow', 'nose', 'left eye', 'right eye',  'mouth']
    #  LANDMAKR_BOUNDARY_300W: [[1, 3, 5, 8, 11, 15, 19, 22, 24],
    #                           [26, 30, 33, 37, 40, 42, 45, 48],
    #                           [49, 50, 51, 52, 53],
    #                           [58, 59, 60, 61, 62],
    #                           [67, 68, 69, 70, 71, 72, 73, 74, 75],
    #                           [78, 80, 83, 84, 86, 88],
    #                           [90, 91, 94, 96, 98, 100],
    #                           [102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]]
  LANDMAKR_BOUNDARY_300W: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], [ 9, 10, 11, 12, 13, 14, 15, 16 ], #left, right chin
                              [ 17, 18, 19, 20, 21 ], [ 22, 23, 24, 25, 26 ], #left right brow
                              [ 27, 28, 29, 30, 31, 32, 33, 34, 35 ], #nose
                              [ 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47 ], #left right eye
                              [ 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 ] ] #mouth
  LANDMAKR_BOUNDARY_COFW: [ [ 28 ], [ ], #left, right chin 1
                              [ 0, 2, 4, 5 ], [ 1, 3, 6, 7 ], #left right brow 8
                              [ 18, 19, 20, 21 ], #nose 4
                              [ 8, 10, 12, 13, 16 ], [ 9, 11, 14, 15, 17 ], #left right eye 10
                              [ 22, 23, 24, 25, 26, 27 ] ] #mouth 6

  LANDMAKR_BOUNDARY_AFLW: [ [ 18 ], [ ], #left, right chin 1
                              [ 0, 1, 2 ], [ 3, 4, 5 ], #left right brow 8
                              [ 12, 13, 14 ], #nose 4
                              [ 6, 7, 8 ], [ 9, 10, 11 ], #left right eye 10
                              [ 15, 16, 17 ] ] #mouth 6

  LANDMAKR_BOUNDARY_WFLW: [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 ], [ 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32 ], #left, right chin
                              [ 33, 34, 35, 36, 37, 38, 39, 40, 41 ], [ 42, 43, 44, 45, 46, 47, 48, 49, 50 ], #left, right brow
                              [ 51, 52, 53, 54, 55, 56, 57, 58, 59 ], # nose
                              [ 60, 61, 62, 63, 64, 65, 66, 67, 96 ], [ 68, 69, 70, 71, 72, 73, 74, 75, 97 ], #left right eye
                              [ 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 ] ] #mouth

[04/28 10:02:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BOUNDARY:
  - left contour
  - right contour
  - left brow
  - right brow
  - nose
  - left eye
  - right eye
  - mouth
  FLIP: true
  INPUT_SIZE:
  - 448
  - 448
  LANDMAKR_BOUNDARY_300W:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
  - - 22
    - 23
    - 24
    - 25
    - 26
  - - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
  - - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
  - - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
  LANDMAKR_BOUNDARY_AFLW:
  - - 18
  - []
  - - 0
    - 1
    - 2
  - - 3
    - 4
    - 5
  - - 12
    - 13
    - 14
  - - 6
    - 7
    - 8
  - - 9
    - 10
    - 11
  - - 15
    - 16
    - 17
  LANDMAKR_BOUNDARY_COFW:
  - - 28
  - []
  - - 0
    - 2
    - 4
    - 5
  - - 1
    - 3
    - 6
    - 7
  - - 18
    - 19
    - 20
    - 21
  - - 8
    - 10
    - 12
    - 13
    - 16
  - - 9
    - 11
    - 14
    - 15
    - 17
  - - 22
    - 23
    - 24
    - 25
    - 26
    - 27
  LANDMAKR_BOUNDARY_WFLW:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
  - - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
  - - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
  - - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
  - - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
  - - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 96
  - - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 97
  - - 76
    - 77
    - 78
    - 79
    - 80
    - 81
    - 82
    - 83
    - 84
    - 85
    - 86
    - 87
    - 88
    - 89
    - 90
    - 91
    - 92
    - 93
    - 94
    - 95
  LANDMARK_INDEX: []
  LANDMARK_INDEX_300W:
  - 1
  - 3
  - 5
  - 8
  - 11
  - 15
  - 19
  - 22
  - 24
  - 26
  - 30
  - 33
  - 37
  - 40
  - 42
  - 45
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 58
  - 59
  - 60
  - 61
  - 62
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 80
  - 83
  - 84
  - 86
  - 88
  - 90
  - 91
  - 94
  - 96
  - 98
  - 100
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 124
  LANDMARK_INDEX_AFLW:
  - 49
  - 51
  - 53
  - 58
  - 60
  - 62
  - 78
  - 122
  - 84
  - 90
  - 123
  - 96
  - 76
  - 70
  - 77
  - 102
  - 120
  - 108
  - 24
  - 124
  LANDMARK_INDEX_COFW:
  - 49
  - 62
  - 53
  - 58
  - 51
  - 56
  - 60
  - 64
  - 78
  - 96
  - 84
  - 90
  - 81
  - 87
  - 93
  - 99
  - 122
  - 123
  - 76
  - 77
  - 70
  - 73
  - 102
  - 108
  - 105
  - 116
  - 120
  - 111
  - 24
  - 124
  LANDMARK_INDEX_WFLW:
  - 0
  - 2
  - 4
  - 6
  - 7
  - 9
  - 10
  - 12
  - 13
  - 14
  - 16
  - 17
  - 18
  - 20
  - 21
  - 23
  - 24
  - 25
  - 27
  - 28
  - 29
  - 31
  - 32
  - 34
  - 35
  - 36
  - 38
  - 39
  - 41
  - 43
  - 44
  - 46
  - 47
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 78
  - 79
  - 81
  - 82
  - 84
  - 85
  - 87
  - 89
  - 90
  - 92
  - 93
  - 95
  - 96
  - 97
  - 99
  - 101
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  MAX_IMAGE_SIZE: 20000
  NUM_LANDMARKS: 68
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROT_FACTOR: 30
  SAMPLE_PER_CLASS: 68
  SAMPLE_SEED: 0
  SCALE_FACTOR: 0.25
  TEST:
  - 300W_val
  - COFW_val
  - AFLW_val
  - WFLW_val
  TRAIN:
  - 300W_train
  - WFLW_train
  - COFW_train
  - AFLW_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_alignment
  FORMAT: RGB
  IMAGE_SIZE: 640
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
  TASK_NAME:
  - 300W.
  - COFW.
  - AFLW.
  - WFLW.
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  CLIP_ADAPTER:
    CLIP_ENSEMBLE: true
    CLIP_ENSEMBLE_WEIGHT: 0.8
    CLIP_MODEL_NAME: ViT-B/16
    MASK_EXPAND_RATIO: 1.0
    MASK_FILL: mean
    MASK_MATTING: false
    MASK_THR: 0.5
    PREDEFINED_PROMPT_TEMPLATES:
    - a sculpture of a {}.
    PROMPT_CHECKPOINT: ./output/prompt_model_0015000.pth
    PROMPT_DIM: 512
    PROMPT_LEARNER: learnable
    PROMPT_SHAPE:
    - 16
    - 0
    REGION_CLIP_ADAPTER:
      CLIP_MODEL_NAME: ViT-B/16
      PREDEFINED_PROMPT_TEMPLATES:
      - a photo of a {}.
      PROMPT_CHECKPOINT: ''
      PROMPT_DIM: 512
      PROMPT_LEARNER: predefined
      PROMPT_SHAPE:
      - 16
      - 0
    REGION_RESIZED: true
    SEPERATE_ADAPTER: false
    TASK_PROMPT_SHAPE: 8
  DEVICE: cuda
  EXTRA:
    AUX_LOSS: true
    DEC_LAYERS: 10
    EOS_COEF: 0.1
    KPT_LOSS_COEF: 5.0
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 1.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 20.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 156
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.5
      OVERLAP_THRESHOLD: 0.5
      PANOPTIC_ON: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: OpenVocabulary
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    EMBEDDING_DIM: 512
    EMBED_DIM: 2048
    EMBED_HIDDEN_DIM: 1024
    EMBED_LAYERS: 2
    EMB_SIZE: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LAND_CLASSES: 125
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerInteractionHead
    NORM: GN
    NUM_CLASSES: 8
    NUM_HEADS: 8
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
    USE_LAYER_SCALE: true
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: null
ORACLE: false
OUTPUT_DIR: ./output
PSEUDO: false
PSEUDO_FLAG_NAME: trainable_flag
PSEUDO_REJECT_THRESHOLD: 0.0
PSEUDO_WITH_PRIOR: true
SEED: 42
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5001
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MODE: predict
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 5.0e-05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DENSE_CRF: false
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  OPTIM:
    LR: 0.001
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_OVERLAP: 0.6666666666666666
  SLIDING_TILE_SIZE: 224
  SLIDING_WINDOW: false
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: null
  PROJECT: zero_shot_seg

[04/28 10:02:46] detectron2 INFO: Full config saved to ./output\config.yaml
[04/28 10:02:48] d2.engine.defaults INFO: Model:
OpenVocabulary(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerInteractionHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): PositionEmbeddingSine()
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): OpenTransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer_self_attention_layers): ModuleList(
        (0-9): 10 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-9): 10 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-9): 10 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(156, 256)
      (query_embed): Embedding(156, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (class_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (landmark_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=512, bias=True)
          (1): Linear(in_features=512, out_features=125, bias=True)
        )
      )
      (landmark_coors): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): Linear(in_features=128, out_features=2, bias=True)
        )
      )
    )
    (interaction): ContextInteraction(
      (layer_norm_q_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layer_norm_k_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (q_proj): Linear(in_features=256, out_features=2048, bias=True)
        (k_proj): Linear(in_features=512, out_features=2048, bias=True)
        (v_proj): Linear(in_features=512, out_features=2048, bias=True)
        (out_proj): Linear(in_features=2048, out_features=256, bias=True)
      )
      (drop_path): Identity()
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 5.0
  )
  (criterion_land): SetCriterion_Wan(
    (matcher): HungarianMatcher_Wan()
  )
  (clip_adapter): MaskFormerClipAdapter(
    (clip_model): CLIP(
      (visual): VisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (prompt_learner): LearnablePromptExtractor(
      prefix_prompt:16,suffix_prompt:0,dimension:512
      [Normal_Init(mu=0,std=0.02)]
    )
  )
)
[04/28 10:03:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 10:03:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 10:03:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 10:03:04] d2.data.build INFO: Making batched data loader with batch_size=8
[04/28 10:03:04] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from None ...
[04/28 10:03:04] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[04/28 10:03:04] d2.engine.train_loop INFO: Starting training from iteration 0
[04/28 10:04:55] d2.evaluation.evaluator INFO: Inference done 101/135. Dataloading: 0.0003 s/iter. Inference: 0.5261 s/iter. Eval: 0.0063 s/iter. Total: 0.5328 s/iter. ETA=0:00:18
